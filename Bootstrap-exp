import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score
from scipy.stats import norm
import matplotlib.pyplot as plt

# Generate synthetic dataset
np.random.seed(42)
n_samples = 1000
X = np.random.rand(n_samples, 10)  # 10 features
y = np.random.randint(0, 2, n_samples)  # Binary target

# Split into training and test sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Initialize model
model = RandomForestClassifier(n_estimators=100, random_state=42)

# Bootstrapping parameters
n_bootstraps = 200  # Number of bootstrap samples
bootstrap_scores = []

# Perform bootstrapping
for _ in range(n_bootstraps):
    # Create a bootstrap sample (sample with replacement)
    indices = np.random.choice(len(X_train), size=len(X_train), replace=True)
    X_bootstrap, y_bootstrap = X_train[indices], y_train[indices]
    
    # Train model on bootstrap sample
    model.fit(X_bootstrap, y_bootstrap)
    
    # Evaluate on test set
    y_pred = model.predict(X_test)
    score = accuracy_score(y_test, y_pred)
    
    bootstrap_scores.append(score)

# Compute mean and confidence interval
mean_score = np.mean(bootstrap_scores)
lower_bound, upper_bound = np.percentile(bootstrap_scores, [2.5, 97.5])  # 95% CI

# Output summary
print(mean_score, (lower_bound, upper_bound))

# Display results
bootstrap_results = pd.DataFrame({'Bootstrap Score': bootstrap_scores})


#  ====== ace_tools is not a reliable package =========
# =====================================================

# import ace_tools as tools
# tools.display_dataframe_to_user(name="Bootstrap Confidence Interval Results", dataframe=bootstrap_results)

# # Plot distribution of bootstrap scores
# plt.figure(figsize=(8, 5))
# plt.hist(bootstrap_scores, bins=30, alpha=0.7, color='b', edgecolor='black')
# plt.axvline(mean_score, color='r', linestyle='dashed', linewidth=2, label=f'Mean: {mean_score:.4f}')
# plt.axvline(lower_bound, color='g', linestyle='dashed', linewidth=2, label=f'95% CI Lower: {lower_bound:.4f}')
# plt.axvline(upper_bound, color='g', linestyle='dashed', linewidth=2, label=f'95% CI Upper: {upper_bound:.4f}')
# plt.xlabel("Accuracy Score")
# plt.ylabel("Frequency")
# plt.title("Bootstrap Distribution of Accuracy Scores")
# plt.legend()
# plt.show()


